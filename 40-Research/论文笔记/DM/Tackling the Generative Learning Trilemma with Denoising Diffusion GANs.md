---
Authors: Zhisheng Xiao, Karsten Kreis, Arash Vahdat
Date: 2022-04-04
Topics: DM
Keywords: 
---
tags: #论文笔记 

## Zotero Links 
* PDF Attachments
	- [arXiv Fulltext PDF](zotero://open-pdf/library/items/TDSRZ626) 
* [Local library](zotero://select/items/1_K3BLQXCH) 

## 1. introduction
在过去的十年中，已经开发了各种各样的深度生成模型。然而，这些模型往往难以同时满足三个关键要求，包括:**高样本质量、模式覆盖和快速采样。**我们把这些要求所带来的挑战称为**生成式学习三难困境**，因为现有的模型经常用一些模型来交换另一些模型。特别是，**去噪扩散模型已经显示出令人印象深刻的样本质量和多样性，但其昂贵的采样还不允许它们应用于许多现实世界的应用。** 在本文中，我们认为这些模型中的缓慢采样**从根本上归因于去噪步骤中的高斯假设，该假设仅适用于小步长。** **为了实现大步骤去噪，从而减少去噪步骤的总数，我们建议使用复杂的多模态分布对去噪分布建模。** 我们引入了去噪扩散生成对抗网络(去噪扩散GAN)，它使用**多模态条件GAN对每个去噪步骤进行建模**。通过广泛的评估，我们表明去噪扩散gan获得了与原始扩散模型竞争的样本质量和多样性，同时在CIFAR-10数据集上的速度快2000倍。与传统GANs相比，我们的模型具有更好的模式覆盖和样本多样性。据我们所知，去噪扩散GAN是第一个在扩散模型中降低采样成本的模型，使其能够廉价地应用于实际应用。

在过去的十年中，已经为图像等各个领域开发了大量的深度生成模型(Karras et al.， 2019;Razavi等人，2019)，音频(Oord等人，2016a;Kong等人，2021)，点云(Yang等人，2019)和图表(De Cao和Kipf, 2018)。然而，目前的生成式学习框架还不能同时满足三个关键要求，而这些要求往往是它们在现实问题中广泛采用所必需的。这些要求包括 **(i)高质量采样，(ii)模式覆盖和样本多样性，以及(iii)快速和计算成本低廉的采样。** 例如，目前大多数图像合成的工作都集中在高质量的生成上。然而，模式覆盖和数据多样性对于更好地代表少数群体和减少生成模型的负面社会影响非常重要。此外，交互式图像编辑或实时语音合成等应用程序需要快速采样。在这里，我们将这些需求所带来的挑战确定为生成学习的三难困境，因为现有的模型通常在它们之间妥协。

---

(i) High-quality sampling ：许多应用程序，尤其是那些直接与用户交互的应用程序，需要高生成质量。例如，在语音生成中，语音质量差是很难理解的。类似地，在图像建模中，期望的输出在视觉上与自然图像无法区分。
(ii) 模式覆盖和样本多样性 ：如果训练数据包含复杂或大量的多样性，一个好的生成模型应该在不牺牲生成质量的情况下成功捕获这种多样性。
(iii) 快速且计算成本低廉的采样 ：许多交互式应用程序需要快速生成，例如实时图像编辑。

---

在本文中，我们通过重新制定去噪扩散模型来解决生成学习的三难困境，专门用于**快速采样，同时保持强大的模式覆盖和样本质量**。我们研究了扩散模型的慢采样问题，我们观察到**扩散模型通常假设去噪分布可以近似为高斯分布。** 然而，**已知高斯假设仅在小去噪步骤的无穷小极限下成立**(Sohl-Dickstein et al.， 2015;Feller, 1949)，**这导致在反向过程中需要大量的步骤**。当反向过程**使用更大的步长(即去噪步骤更少)时，我们需要一个非高斯多模态分布来建模去噪分布**。直观地，在图像合成中，多模态分布产生于这样一个事实，即多个看似干净的图像可能对应于相同的噪声图像。

---
什么是多模态分布？

---


受这一观察结果的启发，我们建议用一个**具有表现力的多模态分布对去噪分布进行参数化，以实现大步长去噪。** 特别地，我们介绍了一种新的生成模型，称为去噪扩散GAN，**其中去噪分布用条件GAN建模。** 在图像生成中，我们观察到我们的模型获得了与扩散模型竞争的样本质量和模式覆盖，**同时只需要两个去噪步骤**，与Song等(2021c)在CIFAR-10上的预测-校正采样相比，实现了约2000倍的采样速度。与传统的GANs相比，我们的模型在样本多样性方面显著优于最先进的GANs，同时在样本保真度方面具有竞争力。

总之，我们做出了以下贡献:i)我们将扩散模型的缓慢采样归因于去噪分布中的高斯假设，并建议采用复杂的多模态去噪分布。ii)我们提出去噪扩散GANs，这是一种扩散模型，其反向过程由条件GANs参数化。iii)通过仔细的评估，我们证明去噪扩散gan在图像生成和编辑方面比当前的扩散模型实现了几个数量级的加速。我们表明，我们的模型在很大程度上克服了深度生成学习的三难困境，**使扩散模型首次适用于交互式的、真实世界的应用程序，计算成本低**

## 2. Background
![[Pasted image 20221213143546.png]]
![[Pasted image 20221213143557.png]]

DM的训练目标是最大化似然pθ(x0)，通过最大化ELBO来得到：
![[Pasted image 20221213143637.png]]
![[Pasted image 20221213143142.png]]

Sohl-Dickstein等人(2015)表明，L可以写成**具有可控制分布的替代形式**(详情请参阅Ho等人(2020)的附录A)。Ho等人(2020)展示了这种形式与使用去噪分数匹配训练的基于分数的模型的等价性(Song & Ermon, 2019;2020)。

DM两个关键：1. 去噪采用高斯分布；2. 去噪的step通常成百上千

## 3. 去噪扩散GANs
### 3.1 为什么学习一个多模态分布可以减少去噪步骤
一般假设：将去噪每一步估计为高斯分布。那什么时候这个估计是准确的？也就是什么时候真的是高斯分布？
1. 步长βt无限小的时候
2. 数据的边缘分布q(xt)是高斯分布的时候，真实的去噪分布自然也是高斯分布的形式：例如LSGM就通过VAE先编码到高斯分布，再用diffusion模型

如果两个条件都不满足？真实的去噪过程的分布会更加复杂和多模态。用一维数据举了例子。
![[Pasted image 20221213202123.png]]
上面：一维数据的前向扩散过程，下面：固定x5条件下，不同步长真是去噪分布的可视化。对于小步长，真正的去噪分布接近高斯分布。随着步长的增加，变得更加复杂和多模态。

---
什么意思？

---

### 3.2 Diffusion GANs
目标：减少去噪过程的步数。
思路：将去噪分布建模为显著的多模态分布？
引入GAN：考虑到条件GAN已经被证明可以在图像域中建模复杂的条件分布，采用它来近似真实的去噪分布。
具体做法：正向扩散和之前类似，主要假设T很小，并且每个扩散补偿有较大的βt。我们的训练是通过对条件GANgenerator产生的pθ和真实分布q做损失函数，使用最小化对抗损失使得每个去噪步骤的散度Dadv。

---
βt是什么

---

Ddav可以是Wasserstein距离，jensen - shannon散度，或f-散度，这取决于对抗性训练设置。本文基于非饱和GAN，被广泛应用于成功的GAN框架例如styleGANs。其中，Dadv采用了f散度的一个特殊的实例，称为softened reverse KL，不同于之前最原始的扩散模型中用的前向KL散度。

---
f散度？
softened reverse KL

---
设置对抗训练：判别器 $D_{\Phi}$ ,训练方式：
![[Pasted image 20221213204557.png]]
看不懂看不懂看不懂，判断xt-1是否是xt的去噪版本。由于第一项的真实分布q是未知的，用另一个形式：
![[Pasted image 20221213213357.png]]
来重写：
![[Pasted image 20221213213421.png]]
给定判别器，可以训练生成器，用非饱和GAN目标来更新生成器
![[Pasted image 20221213213745.png]]

**参数化隐式去噪模型**
DM可以理解为：不直接预测xt-1，而是通过参数化去噪模型，x0通过去噪模型fθ来预测，然后用xt，x0和xt-1之间的先验分布来预测xt-1，
![[Pasted image 20221213213932.png]]

---
什么是先验分布？

---
![[Pasted image 20221213215324.png]]
pθ(x0|xt)是GANgeneratorGθ(xt,z,t)，其中z为L维的隐变量符合N正态分布

本文参数化的优点：pθ和DDPM类似，因此，我们可以从DDPM中借鉴一些归纳偏差，如网络结构设计。主要区别在于，在DDPM中，x0被预测为xt的确定性映射，而在我们的例子中，x0是由具有随机潜在变量z的生成器产生的。与DDPM中的单峰去噪模型相比，这是允许我们的去噪分布pθ(xt−1|xt)变得多模态和复杂的关键区别。其次，请注意，对于不同的t, xt具有不同程度的扰动，因此使用单一网络直接预测不同t下的xt−1可能很困难。然而，在我们的例子中，生成器只需要预测未扰动的x0，然后使用q(xt−1|xt, x0)将扰动加回来。


相对于一次性generator的优势：
一个问题：为什么不直接用GAN来一次性生成样本，而要通过迭代去噪来生成样本。
有很多优于传统GAN的地方，传统GAN：
1. GANs训练不稳定和模型坍塌
2. 从一个复杂分布直接生成样本的困难
3. discriminator只看干净样本时的过拟合问题
我们的模型：
1. 将生成过程分解为几个条件去噪扩散步骤，其中每一步都比较简单，因为xt有很强的条件作用？
2. 扩散过程平滑了数据分布，让discriminator不容易过拟合
3. 所以，展示更好的训练稳定性和模型收敛


## 4 对扩散模型的改进时间线
Song et al. (2021c)：将扩散过程推广到连续时间，并提供了扩散模型和去噪分数匹配的统一视图
Jolicoeur-Martineau et al. (2021b)：在训练的主要目标上增加了一个辅助对抗性损失。这和本文有本质区别，因为他们的辅助对抗损失只是作为一个图像增强器，没有使用潜在变量z，因此，去噪分布仍然是单峰高斯分布
Nachmani et al., 2021：正向过程引入不同的噪声分布
Kingma et al., 2021：联合优化模型和噪声调度schedule
Vahdat et al., 2021：将模型应用到隐空间

扩散模型的一个主要缺陷是由于大量的迭代采样步骤导致采样速度较慢，基于这个的改进：
Luhman & Luhman, 2021：知识蒸馏
San-Roman et al., 2021：学习自适应噪声调度
Song et al., 2021a; Kong & Ping, 2021：引入非马尔可夫扩散过程
Jolicoeur-Martineau et al., 2021a：对连续时间模型使用更好的SDE求解器
**Song et al. (2021a)** ：使用x0采样作为他们方法的关键成分，但是他们的去噪分布仍然是高斯分布

这些方法要么在样本质量上有显著的退化，要么仍然需要许多采样步骤，如我们在第5节所演示的那样。

Gao et al. (2021)：和我们的方法有最近的关联。提出通过条件能量模型（EBM）对单步去噪分布进行建模，跟本文提出的使用expressive 去噪分布的思想一致。但是他们从促进EBM训练的角度来激励他们方法。更重要的是，虽然只需要几个去噪步骤，但是必须使用昂贵的MCMC从每个去噪步骤中采样，使得采样过程缓慢。有~180个网络评估。
Esser et al., 2021a：ImageBART：探讨了用自回归模型对离散潜空间上的扩散过程的去噪分布进行建模，使得采样速度变慢

本文和最近的一些GAN的提高样本质量和多样性方面的进展的文章有关，包括数据增强(Zhao et al., 2020; Karras et al., 2020a), 一致性正则化 (Zhang et al., 2020; Zhao et al., 2021) 和熵正则化 (Dieng et al., 2019). 此外， Meng et al. (2021a) 也讨论了使用平滑分布训练生成模型的思想，用于自回归模型。

## 5 实验
GAN generator采用NCSN++架构（含有一个U-Net架构），条件xt是网络的输入，时间是用来确保条件是在时间t。让隐变量z来控制归一化层，特殊的，将generator 中 NCSN++中所有组归一化层替换为自适应组归一化层。利用一个简单的多层全连接网络，用z预测归一化中的位移和尺度参数。？？

### 克服三难问题
（样本保真度、样本多样性、采样时间）
对CRFAR-10数据集上的模型综合列表进行基准测试
**评估标准**：样本保真度——FID，IS；样本多样性——improved召回评分；采样时间——NFE，clocktime生成一百张图片的时间
V100GPU
**结果**：
table1
1. 样本保真度：即使有些模型有更好的FID和IS，但是他们需要更多的函数评估来生成模型（本文只用了四个去噪步）
2. 图4，只有adaptive data augmentation的styleGAN2的样本质量略好于本文，但是通过table1可以看出，GAN的样本多样性有限，因为recall都低于0.5，本文的recall更好
3. 图5 定性，可视化
![[Pasted image 20221213223618.png]]![[Pasted image 20221213224323.png]]
![[Pasted image 20221213224331.png]]

### 消融实验
1. 去噪步的数量
T=1：训练一个无条件GAN，条件xt不包含任何x0的信息？样本多样性很差（recall）
T=4结果最好
![[Pasted image 20221213224507.png]]

2. 作为数据增强的扩散
GAN加上数据增强，训练一个单次GAN，并将正向扩散过程作为数据增强。table2中的第二组。明显比我们的模型差，表明我们的模型不等同于在应用鉴别器之前增加数据。

3. pθ的参数化
一种：直接让generator输出去噪样本xt-1，而不使用后验采样
一种：输出噪声et来扰乱干净的图像来生成xt，
后一种情况与大多数DM相关，其中网络确定性地预测扰动噪声。
table2的第三组。

4. 隐变量
去除隐变量z，将本文模型转换为单峰分布。table2的第四组。没有任何隐变量，不是多模态分布，样本质量变差。
图8可视化z变量的影响，虽然条件x1中的大部分信息被保留，但由于潜在变量，样本是多样化的。
![[Pasted image 20221213225603.png]]

## 总结
深度生成学习框架仍然在努力解决生成学习的三难困境。扩散模型实现了特别高质量和多样化的采样。但由于采样速度慢、计算成本高，还不能在实际应用中得到广泛应用。在本文中，我们认为扩散模型中缓慢采样的主要来源之一是去噪分布中的高斯假设，这仅适用于非常小的去噪步骤。为了解决这个问题，我们提出了去噪扩散gan，它使用复杂的多模态分布对每个去噪步骤进行建模，使我们能够采取大的去噪步骤。在大量的实验中，我们表明去噪扩散GANs获得了与原始扩散模型竞争的高样本质量和多样性，同时在采样时快了几个数量级。与传统GANs相比，我们提出的模型具有更好的模式覆盖和样本多样性。我们的去噪扩散GAN在很大程度上克服了生成学习的三难困境，使得扩散模型能够以较低的计算成本应用于现实世界的问题。