## 1. InfoNCE loss


## 2. MSE
像素间的差别

## 3. LPIPS
块与块之间的感知损失
Blended Diffusion for Text-driven Editing of Natural Images



## Note
### 过拟合问题
1. 问题
![[Pasted image 20231123154736.png]]
2. 解决：代价函数
减小高次项的参数值
![[Pasted image 20231123154745.png]]


### 梯度检验 Gradient Checking
对一个复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在不容易察觉的错误。就是说，虽然代价函数（Cost function）看上去在不断减小，但最终的结果可能并不是最优解。

为了避免这样的问题，我们采取一种叫做梯度的数值检验（Numerical Gradient Checking）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否符合预期。

对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点，然后计算两个点的平均值用以估计梯度。即对于某个特定的 _θ_ ，我们计算出在 _θ_ - _ϵ_ 处和 _θ_ + _ϵ_ 的代价值（ _ϵ_ 是一个非常小的值，通常选取0.001），然后求两个代价的平均，用以估计在 _θ_ 处的代价值。
![[Pasted image 20231123162848.png]]
$gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps)$

当 _θ_ 是一个向量时，我们则需要对偏导数进行检验。预期情况：
$gradApprox ≈ D$
**注意**：请在开始训练你的模型之前，把梯度检验禁用掉，因为它非常耗时！


