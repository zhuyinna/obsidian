tags:  #深度学习

# Seq2seq 
  刚才的例子其实是 N 对 N 的循环神经网络，即我的输入序列长度是 N, 输出也是对应的 N 长度的序列。其实循环神经网络还有其他的比如: 1 对 N、N 对 1。

  但很多时候我们会遇到输入序列和输出序列不等长的例子但又不是 1 对 N 和 N 对 1，如机器翻译，智能问答，源语言和目标语言的句子往往并没有相同的长度。为此我们引出 RNN 最重要的一个变种：N vs M。这种结构又叫 Encoder-Decoder 模型，也可以称之为 Seq2Seq 模型。
  
  ![[Pasted image 20230323140535.png]]
  还有一种做法是将 c 当作每一步的输入：
  ![[Pasted image 20230323140603.png]]
  可以把 Encoder 和 Decoder 分别看成是 RNN，在 Encoder 中根据输入数据生成一个语义编码 C，C 的获取方式有很多种，最简单的就是把 Encoder 中最后一个隐藏层赋值给 C，也可以对最后一个隐藏状态做一个变换得到 C，还可以对所有的隐藏状态做变换得到 C。
  
  **Attention 注意机制**
  论生成哪个单词，它们使用的输入句子的语义编码 C 都是一样的，没有任何区别。而语义编码 C 是由原句子中的每个单词经过 Encoder 编码产生的，这意味着原句子中任意单词对生成某个目标单词来说影响力都是相同的，这就是模型没有体现出注意力的缘由。
  
  在上边那个例子中在生成“machine”时，"机","器","学",""习"的贡献是相同的，很明显，这是不太合理，显然，"机","器"，对于翻译成"machine"更为重要。所以我们希望在模型翻译"machine"的时候，"机"， "器"两个字的贡献 (权重)更大，当在翻译成"learning"时，"学"，"习"两个字贡献 (权重)更大。
  ![[Pasted image 20230323140842.png]]
  上图中，输入序列上是“机器学习”，因此 Encoder 中的 h1、h2、h3、h4 分别代表“机","器","学","习”的信息，在翻译"macine"时，第一个上下文向量 C1 应该和"机","器"两个字最相关，所以对应的权重 a 比较大，在翻译"learning"时，第二个上下文向量 C2 应该和"学","习"两个字最相关，所以"学","习"对应的权重 a 比较大。
  
  a 其实是一个 0-1 之间的值，a 可以看成是 e 的 softmax 后的结果。
  
  那现在关于**attention**来说就只剩下一个问题了，就是 e 是怎么来的。关于 e 的计算，业界有很多种方法，常用的有以下三种方式:
    1. 计算 Encoder 的序列 h 与 Decoder 的序列 h 的余弦相似度
    2. 在 1 的基础上，乘上一个 Wa，Wa 是需要学习的参数，从学习到 Encoder 和 Decoder 的隐藏的打分 e
    3. 设计一个前馈神经网络，前馈神经网络的输入是 Encoder 和 Decoder 的两个隐藏状态，Va、Wa 都是需要学习的参数
     ![[Pasted image 20230323140910.png|475]]