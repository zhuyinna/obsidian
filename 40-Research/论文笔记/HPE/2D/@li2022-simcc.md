---
Authors: Yanjie Li; Sen Yang; Peidong Liu; Shoukui Zhang; Yunxiao Wang; Zhicheng Wang; Wankou Yang; Shu-Tao Xia
Date: 2022-07-05
Topics: 2D; HPE
DOI: 10.48550/arXiv.2107.03332
Keywords:
---
tags: #è®ºæ–‡ç¬”è®° 

# SimCC: a Simple Coordinate Classification Perspective for Human Pose Estimation


## Abstract
The 2D heatmap-based approaches have dominated Human Pose Estimation (HPE) for years due to high performance. However, the long-standing quantization error problem in the 2D heatmap-based methods leads to several well-known drawbacks: 1) The performance for the low-resolution inputs is limited; 2) To improve the feature map resolution for higher localization precision, multiple costly upsampling layers are required; 3) Extra post-processing is adopted to reduce the quantization error. To address these issues, we aim to explore a brand new scheme, called \textit{SimCC}, which reformulates HPE as two classification tasks for horizontal and vertical coordinates. The proposed SimCC uniformly divides each pixel into several bins, thus achieving \emph{sub-pixel} localization precision and low quantization error. Benefiting from that, SimCC can omit additional refinement post-processing and exclude upsampling layers under certain settings, resulting in a more simple and effective pipeline for HPE. Extensive experiments conducted over COCO, CrowdPose, and MPII datasets show that SimCC outperforms heatmap-based counterparts, especially in low-resolution settings by a large margin.

## Files and Links
- **Url**: [Open online](http://arxiv.org/abs/2107.03332)
- **zotero entry**: [Zotero](zotero://select/library/items/4V6I2TMX)
- **open pdf**: [arXiv.org Snapshot](zotero://open-pdf/library/items/9A3PQUFC); [Li et al_2022_SimCC.pdf](zotero://open-pdf/library/items/8L3NIINX)

## Comments


---

## Summary

  
## Research Objective(s)


## Background / Problem Statement


## Method(s)


## Evaluation


## Conclusion


## Notes


----

## Extracted Annotations

æ³¨é‡Š(2023/4/19 ä¸‹åˆ9:42:39)

<mark style="background: red;">1) The performance for the low-resolution inputs is limited; 2) To improve the feature map resolution for higher localization precision, multiple costly upsampling layers are required; 3) Extra post-processing is adopted to reduce the quantization error</mark> [(Li ç­‰, 2022, p. 1)](zotero://open-pdf/library/items/8L3NIINX?page=1&annotation=Z3V2P2KB)   
> ğŸ”¤1ï¼‰ä½åˆ†è¾¨ç‡è¾“å…¥çš„æ€§èƒ½æœ‰é™ï¼› 2ï¼‰ä¸ºäº†æé«˜ç‰¹å¾å›¾åˆ†è¾¨ç‡ä»¥è·å¾—æ›´é«˜çš„å®šä½ç²¾åº¦ï¼Œéœ€è¦å¤šä¸ªæ˜‚è´µçš„ä¸Šé‡‡æ ·å±‚ï¼› 3ï¼‰é‡‡ç”¨é¢å¤–çš„åå¤„ç†æ¥å‡å°‘é‡åŒ–è¯¯å·®ğŸ”¤  

<mark style="background: green;">which reformulates HPE as two classification tasks for horizontal and vertical coordinates. The proposed SimCC uniformly divides each pixel into several bins, thus achieving sub-pixel localization precision and low quantization error.</mark> [(Li ç­‰, 2022, p. 1)](zotero://open-pdf/library/items/8L3NIINX?page=1&annotation=L359495D)   
> ğŸ”¤å®ƒå°† HPE é‡æ–°è¡¨è¿°ä¸ºæ°´å¹³å’Œå‚ç›´åæ ‡çš„ä¸¤ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚æ‰€æå‡ºçš„ SimCC å°†æ¯ä¸ªåƒç´ ç»Ÿä¸€åˆ’åˆ†ä¸ºå¤šä¸ª binï¼Œä»è€Œå®ç°äºšåƒç´ å®šä½ç²¾åº¦å’Œä½é‡åŒ–è¯¯å·®ã€‚ğŸ”¤  

<mark style="background: yellow;">Extensive experiments conducted over COCO, CrowdPose, and MPII datasets</mark> [(Li ç­‰, 2022, p. 1)](zotero://open-pdf/library/items/8L3NIINX?page=1&annotation=PH269VL8)   
> ğŸ”¤åœ¨ COCOã€CrowdPose å’Œ MPII æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒğŸ”¤  

<mark style="background: yellow;">1) a backbone to extract keypoint representations; 2) a regression head to generate the 2D heatmap, which may consist of multiple time-consuming upsampling layers; 3) extra post-processing to refine the predictions, such as empirical shift and DARK</mark> [(Li ç­‰, 2022, p. 2)](zotero://open-pdf/library/items/8L3NIINX?page=2&annotation=HR5I643L)   
> ğŸ”¤1ï¼‰æå–å…³é”®ç‚¹è¡¨ç¤ºçš„ä¸»å¹²ï¼› 2) ä¸€ä¸ªå›å½’å¤´æ¥ç”ŸæˆäºŒç»´çƒ­å›¾ï¼Œå®ƒå¯èƒ½ç”±å¤šä¸ªè€—æ—¶çš„ä¸Šé‡‡æ ·å±‚ç»„æˆï¼› 3) é¢å¤–çš„åå¤„ç†ä»¥æ”¹è¿›é¢„æµ‹ï¼Œä¾‹å¦‚ç»éªŒåç§»å’Œ DARKğŸ”¤  

<mark style="background: green;">Different from these heatmap-based schemes, the proposed SimCC is much simpler, which only needs two classifier heads for coordinate classification and excludes the costly refinement post-processing and extra upsampling layers.</mark> [(Li ç­‰, 2022, p. 2)](zotero://open-pdf/library/items/8L3NIINX?page=2&annotation=79NCKBP7)   
> ğŸ”¤ä¸è¿™äº›åŸºäºçƒ­å›¾çš„æ–¹æ¡ˆä¸åŒï¼Œæ‰€æå‡ºçš„ SimCC æ›´ç®€å•ï¼Œå®ƒåªéœ€è¦ä¸¤ä¸ªåˆ†ç±»å™¨å¤´è¿›è¡Œåæ ‡åˆ†ç±»ï¼Œå¹¶ä¸”ä¸åŒ…æ‹¬æ˜‚è´µçš„ç»†åŒ–åå¤„ç†å’Œé¢å¤–çš„ä¸Šé‡‡æ ·å±‚ã€‚ğŸ”¤  

<mark style="background: green;">we propose a simple yet effective coordinate classification pipeline, namely SimCC, which regards HPE as two classification tasks for horizontal and vertical coordinates.</mark> [(Li ç­‰, 2022, p. 2)](zotero://open-pdf/library/items/8L3NIINX?page=2&annotation=NDN3PB4V)   
> ğŸ”¤æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„åæ ‡åˆ†ç±»ç®¡é“ï¼Œå³ SimCCï¼Œå®ƒå°† HPE è§†ä¸ºæ°´å¹³å’Œå‚ç›´åæ ‡çš„ä¸¤ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚ğŸ”¤  

<mark style="background: yellow;">SimCC firstly employs a Convolutional Neural Network (CNN) or Transformer-based backbone to extract keypoint representations. Given the obtained keypoint representations, SimCC then performs coordinate classification for vertical and horizontal coordinates independently to yield the final predictions.</mark> [(Li ç­‰, 2022, p. 2)](zotero://open-pdf/library/items/8L3NIINX?page=2&annotation=P7BXH95R)   
> ğŸ”¤SimCC é¦–å…ˆé‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œ (CNN) æˆ–åŸºäº Transformer çš„ä¸»å¹²æ¥æå–å…³é”®ç‚¹è¡¨ç¤ºã€‚ç»™å®šè·å¾—çš„å…³é”®ç‚¹è¡¨ç¤ºï¼ŒSimCC ç„¶åç‹¬ç«‹åœ°å¯¹å‚ç›´å’Œæ°´å¹³åæ ‡è¿›è¡Œåæ ‡åˆ†ç±»ä»¥äº§ç”Ÿæœ€ç»ˆé¢„æµ‹ã€‚ğŸ”¤  

<mark style="background: yellow;">SimCC uniformly divides each pixel into several bins, which achieves sub-pixel localization precision.</mark> [(Li ç­‰, 2022, p. 3)](zotero://open-pdf/library/items/8L3NIINX?page=3&annotation=WN4TXEME)   
> ğŸ”¤SimCC å°†æ¯ä¸ªåƒç´ ç»Ÿä¸€åˆ’åˆ†ä¸ºå¤šä¸ª binï¼Œä»è€Œå®ç°äº†äºšåƒç´ å®šä½ç²¾åº¦ã€‚ğŸ”¤  

<mark style="background: green;">reformulating the problem as two classification tasks for horizontal and vertical coordinates. SimCC serves as a general scheme and can be easily applied to existing CNN-based or Transformer-based HPE models.</mark> [(Li ç­‰, 2022, p. 3)](zotero://open-pdf/library/items/8L3NIINX?page=3&annotation=UQHUECUA)   
> ğŸ”¤å°†é—®é¢˜é‡æ–°è¡¨è¿°ä¸ºæ°´å¹³å’Œå‚ç›´åæ ‡çš„ä¸¤ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚ SimCC ä½œä¸ºä¸€ç§é€šç”¨æ–¹æ¡ˆï¼Œå¯ä»¥è½»æ¾åº”ç”¨äºç°æœ‰çš„åŸºäº CNN æˆ–åŸºäº Transformer çš„ HPE æ¨¡å‹ã€‚ğŸ”¤  

<mark style="background: green;">SimCC achieves high efficiency by omitting the extra time-consuming upsampling and post-processing in heatmap-based methods.</mark> [(Li ç­‰, 2022, p. 3)](zotero://open-pdf/library/items/8L3NIINX?page=3&annotation=GJE3BZB9)   
> ğŸ”¤SimCC é€šè¿‡çœç•¥åŸºäºçƒ­å›¾çš„æ–¹æ³•ä¸­é¢å¤–è€—æ—¶çš„ä¸Šé‡‡æ ·å’Œåå¤„ç†æ¥å®ç°é«˜æ•ˆç‡ã€‚ğŸ”¤  

<mark style="background: green;">verify the effectiveness of the proposed SimCC with different backbones and multiple input sizes.</mark> [(Li ç­‰, 2022, p. 3)](zotero://open-pdf/library/items/8L3NIINX?page=3&annotation=47YPRJAE)   
> ğŸ”¤éªŒè¯æ‰€æå‡ºçš„å…·æœ‰ä¸åŒä¸»å¹²å’Œå¤šä¸ªè¾“å…¥å¤§å°çš„ SimCC çš„æœ‰æ•ˆæ€§ã€‚ğŸ”¤  

<mark style="background: yellow;">Coordinate classification. Concurrent to our work, Chen et al. [5] propose Pix2Seq to casts object detection as a language modeling task, where an object is described as sequences of five discrete tokens for further classification. In Pix2Seq, the Transformer decoder architecture is essential to â€œread outâ€ each object (yield the predictions)</mark> [(Li ç­‰, 2022, p. 4)](zotero://open-pdf/library/items/8L3NIINX?page=4&annotation=RLLC2UWI)    

![](file://C:/Users/%E7%A5%9D%E9%93%B6%E9%82%A3/Documents/Obsidian%20Vault/.hidden/zotero/storage/3CRES83X%5Cimage.png)[ ](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=UMDRQBRU)

<mark style="background: orange;">CNNbased or Transformer-based network (e.g., HRNet [29], TokenPose [18])</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=P6QSCEFE)   
> ğŸ”¤åŸºäº CNN æˆ–åŸºäº Transformer çš„ç½‘ç»œï¼ˆä¾‹å¦‚ï¼ŒHRNet [29]ã€TokenPose [18]ï¼‰ğŸ”¤  

<mark style="background: orange;">after the backbone to perform coordinate classification</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=N3N2M2PA)   
> ğŸ”¤åœ¨ä¸»å¹²ä¹‹åè¿›è¡Œåæ ‡åˆ†ç±»ğŸ”¤  

<mark style="background: orange;">For the CNN-based backbone, we simply flatten the outputted keypoint representations from (n, Hâ€², W â€²) to (n, Hâ€² Ã— W â€²) for classification.</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=XPKWXY2L)   
> ğŸ”¤å¯¹äºåŸºäº CNN çš„ä¸»å¹²ï¼Œæˆ‘ä»¬ç®€å•åœ°å°†è¾“å‡ºçš„å…³é”®ç‚¹è¡¨ç¤ºä» (n, H', W ') å±•å¹³åˆ° (n, H' Ã— W ') ä»¥è¿›è¡Œåˆ†ç±»ã€‚ğŸ”¤  

<mark style="background: gray;">Compared to heatmap-based approach [38] which uses multiple costly deconvolution layers as head</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=MN6LA2CY)   
> ğŸ”¤ä¸ä½¿ç”¨å¤šä¸ªæ˜‚è´µçš„åå·ç§¯å±‚ä½œä¸ºå¤´éƒ¨çš„åŸºäºçƒ­å›¾çš„æ–¹æ³•[38]ç›¸æ¯”ğŸ”¤  

<mark style="background: orange;">To achieve classification, we propose to uniformly discretize each continuous coordinate value into an integer as class label for model training:</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=HQ2HCQBV)   
> ğŸ”¤ä¸ºäº†å®ç°åˆ†ç±»ï¼Œæˆ‘ä»¬å»ºè®®å°†æ¯ä¸ªè¿ç»­åæ ‡å€¼ç»Ÿä¸€ç¦»æ•£åŒ–ä¸ºä¸€ä¸ªæ•´æ•°ä½œä¸ºæ¨¡å‹è®­ç»ƒçš„ç±»æ ‡ç­¾ï¼šğŸ”¤  

<mark style="background: orange;">To yield the final prediction, SimCC performs vertical and horizontal coordinate classification independently based on the n keypoint representations learnt by the backbone.</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=IWAHQUMR)   
> ğŸ”¤ä¸ºäº†äº§ç”Ÿæœ€ç»ˆçš„é¢„æµ‹ï¼ŒSimCC åŸºäºä¸»å¹²å­¦ä¹ çš„ n ä¸ªå…³é”®ç‚¹è¡¨ç¤ºç‹¬ç«‹åœ°æ‰§è¡Œå‚ç›´å’Œæ°´å¹³åæ ‡åˆ†ç±»ã€‚ğŸ”¤  

<mark style="background: orange;">In addition, Kullbackâ€“Leibler divergence is used as loss function for training.</mark> [(Li ç­‰, 2022, p. 5)](zotero://open-pdf/library/items/8L3NIINX?page=5&annotation=CTPZB94Q)   
> ğŸ”¤æ­¤å¤–ï¼ŒKullbackâ€“Leibler æ•£åº¦ç”¨ä½œè®­ç»ƒçš„æŸå¤±å‡½æ•°ã€‚ğŸ”¤  

<mark style="background: orange;">the closer the output category is to the groundtruth, the better. To address this issue, we also explore to use Laplace or Gaussian label smoothing, resulting in smoothed labels following corresponding distribution.</mark> [(Li ç­‰, 2022, p. 6)](zotero://open-pdf/library/items/8L3NIINX?page=6&annotation=VUZFSNDW)   
> ğŸ”¤è¾“å‡ºç±»åˆ«è¶Šæ¥è¿‘ groundtruth è¶Šå¥½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æˆ–é«˜æ–¯æ ‡ç­¾å¹³æ»‘ï¼Œä»è€Œä½¿å¹³æ»‘æ ‡ç­¾éµå¾ªç›¸åº”çš„åˆ†å¸ƒã€‚ğŸ”¤  

![](file://C:/Users/%E7%A5%9D%E9%93%B6%E9%82%A3/Documents/Obsidian%20Vault/.hidden/zotero/storage/YY4HRNHH%5Cimage.png)[ ](zotero://open-pdf/library/items/8L3NIINX?page=7&annotation=RJJV3Q57)

- [ ] <mark style="background: blue;">5. Chen, T., Saxena, S., Li, L., Fleet, D.J., Hinton, G.: Pix2seq: A language modeling framework for object detection. arXiv preprint arXiv:2109.10852 (2021)</mark> [(Li ç­‰, 2022, p. 16)](zotero://open-pdf/library/items/8L3NIINX?page=16&annotation=F2PBDLMG)  ğŸ”¤5. Chen, T., Saxena, S., Li, L., Fleet, D.J., Hinton, G.ï¼šPix2seqï¼šç”¨äºå¯¹è±¡æ£€æµ‹çš„è¯­è¨€å»ºæ¨¡æ¡†æ¶ã€‚ arXiv é¢„å°æœ¬ arXiv:2109.10852 (2021)ğŸ”¤ 

- [ ] <mark style="background: blue;">32. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2818â€“2826 (2016)</mark> [(Li ç­‰, 2022, p. 17)](zotero://open-pdf/library/items/8L3NIINX?page=17&annotation=LVXWFG4P)  ğŸ”¤32. Szegedy, C.ã€Vanhoucke, V.ã€Ioffe, S.ã€Shlens, J.ã€Wojna, Z.ï¼šé‡æ–°æ€è€ƒè®¡ç®—æœºè§†è§‰çš„èµ·å§‹æ¶æ„ã€‚åœ¨ï¼šIEEE è®¡ç®—æœºè§†è§‰å’Œæ¨¡å¼è¯†åˆ«ä¼šè®®è®ºæ–‡é›†ã€‚ç¬¬ 2818â€“2826 é¡µï¼ˆ2016 å¹´ï¼‰ğŸ”¤ 



