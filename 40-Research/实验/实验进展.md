1. 2.28
在output.7增加一层自注意力，训练7及以后的所有层。
修改ddim_steps，按照论文的公式计算x0

CUDA_VISIBLE_DEVICES='0,1,2,3' torchrun  --nproc_per_node=4 train_addSPL.py --dataset_path "./dataset/deepfashion" --batch_size=8 --exp_name "initial_selfattn" --epoch_nums=20

## prepare
### 数据集
in_shop解压密码：
The image zip file passwords are listed as follows:
  - In-shop Clothes Retrieval Benchmark: mmlab_DeepFashion_inshop
  - Consumer-to-shop Clothes Retrieval Benchmark: mmlab_DeepFashion_consumer2shop
  - Fashion Synthesis Benchmark: mmlab_DeepFashion_fashionsynth

scp：
`scp -rP 31882 C:\Users\15316\Downloads\Google\img_highres root@connect.bjb1.seetacloud.com:/autodl-tmp`


### 密码/token
1. wandb
wandb token：
84c2449dcbd06f656a2e0e79a79d42d00debbbec
杀掉进程：
`ps aux|grep wandb|grep -v grep | awk '{print $2}'|xargs kill -9`

2. ssh
ssh -p 31882 root@connect.bjb1.seetacloud.com
Lwd5gZOYP3p/

## train

bash scripts/single_gpu/pose_transfer_train.sh 0
bash scripts/multi_gpu/pose_transfer_test.sh 1,2,3, MODEL.PRETRAINED_PATH checkpoints

参数量：
total number of parameters:      1097423356
number of trainable parameters: 248224312

## inference

bash scripts/single_gpu/pose_transfer_test.sh 0 MODEL.PRETRAINED_PATH outputs/CFLD/debug/epochs_001/checkpoints


## 存在的问题
<<<<<<< HEAD


haha
=======
>>>>>>> origin/dev
