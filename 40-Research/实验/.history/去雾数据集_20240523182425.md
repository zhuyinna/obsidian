# 数据集
## D-HAZY

下载地址：http://m6z.cn/5IBatp

D-HAZY，建立在Middelbury 和NYU深度数据集上，这些数据集提供各种场景的图像及其相应的[深度图](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%9B%BE&spm=1001.2101.3001.7020)。包含1400多对图像的数据集，其中包括同一场景的地面真实参考图像和模糊图像。

## RESIDE

合成数据集：

下载地址：http://m6z.cn/5IBauH

RESIDE数据集包括合成和真实世界的模糊图像，称为REalistic Single Image Dehazing，RESIDE突出显示了各种数据源和图像内容，并分为五个子集，每个子集用于不同的训练或评估目的。提供了各种各样的去雾算法评估标准，从完整参考度量，无参考度量，到主观评估和任务驱动评估。

<img src=https://s2.loli.net/2024/05/23/XIyubd7znrZNU1D.png width='100%'>



## Middlebury Stereo双目立体匹配测试数据集
下载地址：http://m6z.cn/5Prq8G

这24个数据集是由潘广汉、孙天生、托比·威德和丹尼尔·沙尔斯坦在2019-2021期间创建的。数据集包括11个场景，在许多不同的照明条件和曝光（包括移动设备的闪光灯和“手电筒”照明）下，从1-3个不同的观看方向成像。


<img src=https://s2.loli.net/2024/05/23/aXKJlT41dsB8hU2.png width='100%'>


## NH-HAZE

下载地址：http://m6z.cn/5tyN0D

这是一个非均匀的真实数据集，具有成对的真实雾度和相应的无雾度图像。这是第一个非齐次图像去模糊数据集，包含55个室外场景。在场景中引入了非均匀雾，使用专业雾发生器模拟雾场景的真实条件。
<img src=https://s2.loli.net/2024/05/23/e4HnItoGxyz2hNw.png width='100%'>

## DENSE-HAZE
下载地址：http://m6z.cn/5tyMZP

单图像去叠是一个不适定问题，最近引起了重要关注。尽管在过去几年中，人们对去雾的兴趣显著增加，但由于缺乏真实的雾度和相应的无雾度参考图像对，去雾方法的验证在很大程度上仍然不令人满意。为了解决这一局限性，我们引入了一种新的去雾数据集稠密雾。《DENSE-HAZE》以浓密均匀的朦胧场景为特征，包含33对真实的朦胧图像和各种室外场景的相应无霾图像。通过引入由专业雾霾机器生成的真实雾霾来记录雾霾场景。朦胧和无朦胧的对应场景包含在相同照明参数下捕获的相同视觉内容。

<img src=https://s2.loli.net/2024/05/23/xBfCA1K6omYiPQa.png width='100%'>

## REVIDE视频去雾数据集

下载地址：http://m6z.cn/6bVqYX

现有的深度学习去雾方法多采用单帧去雾数据集进行训练和评测，从而使得去雾网络只能利用当前有雾图像的信息恢复清晰图像。另外一方面，理想中的视频去雾算法却可以使用相邻的有雾帧来获取更多的时空冗余信息，从而得到更好的去雾效果，但由于视频去雾数据集的缺失，视频去雾算法鲜有研究。为了实现视频去雾算法的监督训练，我们首次提出了一组真实的视频去雾数据集（REVIDE）。使用精心设计的视频采集系统，成功地在同一场景进行两次采集，从而同时记录下真实世界中成对且完美对齐的有雾和无雾视频。


# 0. 准备
1. 总共需要多少张图片？ 怎么切片？每隔几帧保存图片？
2. 代表性样本怎么选取？不同类型的雾气密度
3. 选用什么模型来进行深度估计？
4. 视频帧提取出来之后， 怎么增强？ 去噪？
5. 标注： 手动标注还是半自动标注？ 如果半自动标注， 选择哪个去雾算法？
6. 数据集构建： 
   - 数据对： 创建雾图像和对应的图像（或者深度图）的配对数据
   - 数据分割： 分割训练集，验证集，测试集。 怎么分割？
   - 存储格式： jpg还是png
7. 数据集验证：
   - 质量检查： 检查每个样本， 确保groudtruth质量良好
   - 一致性检查：确保雾图像和参考图像是同一个场景
8. 模型训练与验证
   - 如何验证数据集的可靠性？
9. 数据集发布

# 1. 深度估计

## 1.1 有监督

-  基于回归

**基于的损失函数**
基于损失监督学习的单眼图像深度预测训练了一个卷积神经网络，该网络根据预测的深度值与真实深度值之间的偏差设计各种目标函数。最明显的方式是正常距离，如L1或L2规范距离。为了从这两种损失中受益，[45]中使用了反向Huber。当残差小于给定阈值c时，BerHu损耗等于L1损耗，否则为L2损耗.

**可以分为基于patch和基于图像:**
- patch
基于patch的方法首先将图像分割成多个patch或超像素。每个超像素被输入一个CNN来预测一个深度值。通过这种方式，每个超像素都与深度标签相关联。然后使用一些像CRF这样的图形模型来产生像素级深度值。Li et al.[42]从图像中获取超像素，利用CNN进行超像素级深度预测回归。利用层次化的条件随机场将结果细化到像素级。利用两个卷积神经网络在[41]中执行全局深度推理和局部深度推理。两个CNNS的结果通过分层CRF融合得到最终的像素级深度图。全局预测可以减少局部二义性，局部预测提供详细的结构和边界。两种方法都利用CRF作为后处理步骤。

- 图像
基于patch的方法更注重局部信息，而没有很好地利用全局信息。全局信息对于像素之间的相对深度差至关重要。因此，从整个图像进行深度估计变得流行起来。与基于patch的方法不同，基于image的方法以整个图像作为输入，直接预测像素级的深度。Eigen等人[40]首先提出了一个由两个卷积神经网络叠加在一起的粗到细的框架。粗尺度网络由5个卷积神经块和两个全连接层组成，用于提取全局信息。细尺度网络通过全卷积神经网络利用局部信息对粗深度预测结果进行细化。

**优化方向:**
- 优化模块提取深度信息
新的模块设计用于从图像中提取深度相关信息。Laina等人[45]设计了一种全卷积残差网络用于深度预测。他们利用流行的残差神经网络来提取全局信息，并设计一个高效的残差上采样块来获得更高分辨率的深度图。
- 多任务学习: 例如
  - Eigen等人[44]设计了一个多尺度网络，用于训练深度、表面法线和语义标签。
  > 一方面，表面法线是由三维点的局部表面切线平面确定的，切线平面可以由深度估计;另一方面，深度受曲面法线确定的局部曲面切线平面的约束。表面法线通过残差模块进行更新。通过几何约束，使深度曲面法向几何一致，精度更高。
  - 表面法线通过残差模块进行更新。通过几何约束，使深度曲面法向几何一致，精度更高。

### 1.1.2 基于分类


他们将深度值分成许多类别，并训练CNN来确定像素属于哪一类。为了获得连续的深度值，基于CRFs或概率评分进行后处理步骤。**Cao等人[52]将连续的深度值离散化为几个大小相同的bins，并使用CNN来确定像素所属的bins**。根据分类结果和输入图像，**使用全连通CRF生成最终的连续深度预测图。**李等人。

基于分类的方法通过后处理步骤估计最终的密集深度图，而基于回归的方法直接从具有全局和局部信息的图像中学习深度值。

缺陷: 需要有GT,对数据集要求高

## 1.2 无监督

- 基于双目立体图像
   - 通过立体图像的视差来估计深度
   

- 基于视频
  - 考虑到收集双目立体图像需要特殊仪器，单目视频可以很好地替代立体图像。基于单目视频的方法也利用光度损失来监督训练。它们不是将立体图像对作为输入，而是将多个连续图像作为输入，并预测目标图像的相应深度图以及目标图像和相邻图像之间的相对位姿。利用预测的深度、相对位姿和附近图像重建目标图像。
  - 相邻视频帧之间的时间相关性有助于深度预测。张等人[86]设计了一种**基于卷积长短时记忆（LSTM）的网络结构**，以利用视频之间的时空信息。他们利用三维卷积神经网络作为鉴别器discriminator，将视频序列作为输入来正则化深度生成器generator. 

**稀疏样本指导**




1. 着色方式
   《Levin, Anat, et al. “Colorization Using Optimization.” ACM Transactions on Graphics, Aug. 2004, pp. 689–94, https://doi.org/10.1145/1015706.1015780.  》
   
   用于 inpaint depth maps of the indoor NYU Depth dataset， 这种内嵌的深度图已经被用于最先进的去雾方法  ：
   《Ren, Wenqi, et al. “Single Image Dehazing via Multi-Scale Convolutional Neural Networks.” Computer Vision – ECCV 2016,Lecture Notes in Computer Science, 2016, pp. 154–69, https://doi.org/10.1007/978-3-319-46475-6_10. 》