# 数据集
## D-HAZY

下载地址：http://m6z.cn/5IBatp

D-HAZY，建立在Middelbury 和NYU深度数据集上，这些数据集提供各种场景的图像及其相应的[深度图](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%9B%BE&spm=1001.2101.3001.7020)。包含1400多对图像的数据集，其中包括同一场景的地面真实参考图像和模糊图像。

## RESIDE

合成数据集：

下载地址：http://m6z.cn/5IBauH

RESIDE数据集包括合成和真实世界的模糊图像，称为REalistic Single Image Dehazing，RESIDE突出显示了各种数据源和图像内容，并分为五个子集，每个子集用于不同的训练或评估目的。提供了各种各样的去雾算法评估标准，从完整参考度量，无参考度量，到主观评估和任务驱动评估。

<img src=https://s2.loli.net/2024/05/23/XIyubd7znrZNU1D.png width='100%'>



## Middlebury Stereo双目立体匹配测试数据集
下载地址：http://m6z.cn/5Prq8G

这24个数据集是由潘广汉、孙天生、托比·威德和丹尼尔·沙尔斯坦在2019-2021期间创建的。数据集包括11个场景，在许多不同的照明条件和曝光（包括移动设备的闪光灯和“手电筒”照明）下，从1-3个不同的观看方向成像。


<img src=https://s2.loli.net/2024/05/23/aXKJlT41dsB8hU2.png width='100%'>


## NH-HAZE

下载地址：http://m6z.cn/5tyN0D

这是一个非均匀的真实数据集，具有成对的真实雾度和相应的无雾度图像。这是第一个非齐次图像去模糊数据集，包含55个室外场景。在场景中引入了非均匀雾，使用专业雾发生器模拟雾场景的真实条件。
<img src=https://s2.loli.net/2024/05/23/e4HnItoGxyz2hNw.png width='100%'>

## DENSE-HAZE
下载地址：http://m6z.cn/5tyMZP

单图像去叠是一个不适定问题，最近引起了重要关注。尽管在过去几年中，人们对去雾的兴趣显著增加，但由于缺乏真实的雾度和相应的无雾度参考图像对，去雾方法的验证在很大程度上仍然不令人满意。为了解决这一局限性，我们引入了一种新的去雾数据集稠密雾。《DENSE-HAZE》以浓密均匀的朦胧场景为特征，包含33对真实的朦胧图像和各种室外场景的相应无霾图像。通过引入由专业雾霾机器生成的真实雾霾来记录雾霾场景。朦胧和无朦胧的对应场景包含在相同照明参数下捕获的相同视觉内容。

<img src=https://s2.loli.net/2024/05/23/xBfCA1K6omYiPQa.png width='100%'>

## REVIDE视频去雾数据集

下载地址：http://m6z.cn/6bVqYX

现有的深度学习去雾方法多采用单帧去雾数据集进行训练和评测，从而使得去雾网络只能利用当前有雾图像的信息恢复清晰图像。另外一方面，理想中的视频去雾算法却可以使用相邻的有雾帧来获取更多的时空冗余信息，从而得到更好的去雾效果，但由于视频去雾数据集的缺失，视频去雾算法鲜有研究。为了实现视频去雾算法的监督训练，我们首次提出了一组真实的视频去雾数据集（REVIDE）。使用精心设计的视频采集系统，成功地在同一场景进行两次采集，从而同时记录下真实世界中成对且完美对齐的有雾和无雾视频。


# 0. 准备
1. 总共需要多少张图片？ 怎么切片？每隔几帧保存图片？
2. 代表性样本怎么选取？不同类型的雾气密度
3. 选用什么模型来进行深度估计？
4. 视频帧提取出来之后， 怎么增强？ 去噪？
5. 标注： 手动标注还是半自动标注？ 如果半自动标注， 选择哪个去雾算法？
6. 数据集构建： 
   - 数据对： 创建雾图像和对应的图像（或者深度图）的配对数据
   - 数据分割： 分割训练集，验证集，测试集。 怎么分割？
   - 存储格式： jpg还是png
7. 数据集验证：
   - 质量检查： 检查每个样本， 确保groudtruth质量良好
   - 一致性检查：确保雾图像和参考图像是同一个场景
8. 模型训练与验证
   - 如何验证数据集的可靠性？
9. 数据集发布

# 1. 深度估计

## 1.1 基于回归

可以分为基于patch和基于图像:
- patch
基于patch的方法首先将图像分割成多个patch或超像素。每个超像素被输入一个CNN来预测一个深度值。通过这种方式，每个超像素都与深度标签相关联。然后使用一些像CRF这样的图形模型来产生像素级深度值。Li et al.[42]从图像中获取超像素，利用CNN进行超像素级深度预测回归。利用层次化的条件随机场将结果细化到像素级。利用两个卷积神经网络在[41]中执行全局深度推理和局部深度推理。两个CNNS的结果通过分层CRF融合得到最终的像素级深度图。全局预测可以减少局部二义性，局部预测提供详细的结构和边界。两种方法都利用CRF作为后处理步骤。

-推昂

## 1.2 基于分类

他们将深度值分成许多类别，并训练CNN来确定像素属于哪一类。为了获得连续的深度值，基于CRFs或概率评分进行后处理步骤。Cao等人[52]将连续的深度值离散化为几个大小相同的bins，并使用CNN来确定像素所属的bins。根据分类结果和输入图像，使用全连通CRF生成最终的连续深度预测图。李等人。

1. 着色方式
   《Levin, Anat, et al. “Colorization Using Optimization.” ACM Transactions on Graphics, Aug. 2004, pp. 689–94, https://doi.org/10.1145/1015706.1015780.  》
   
   用于 inpaint depth maps of the indoor NYU Depth dataset， 这种内嵌的深度图已经被用于最先进的去雾方法  ：
   《Ren, Wenqi, et al. “Single Image Dehazing via Multi-Scale Convolutional Neural Networks.” Computer Vision – ECCV 2016,Lecture Notes in Computer Science, 2016, pp. 154–69, https://doi.org/10.1007/978-3-319-46475-6_10. 》