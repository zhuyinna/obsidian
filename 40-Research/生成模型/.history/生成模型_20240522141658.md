

# 生成模型大类

## 自回归模型(Autoregressive Models)
自回归模型是一种生成模型，它通过对数据的先前部分进行建模来预测下一个数据点。典型的自回归模型包括RNN和Transformer.

## 生成对抗网络(Generative Adversarial Networks，GANS)
由生成器和判别器组成，通过对抗训练的方式学习生成数据。生成器试图生成逼真的样本，而判别器则试图区分生成的样本和真实样本。Generator接收一个随机噪声向量作为输入，并通过网络结构将其映射到生成样本空间。噪声向量可以被视为生成器的输入信号，它在训练过程中被用来生成样本使生成器能够学习生成与真实样本相似的数据。

## 变分自编码器(Variational Autoencoders，VAES)
是一种基于概率编码和解码的生成模型。编码器将输入数据转换为潜在变量(通常是高斯分布)的均值和方差参数，并从潜在变量中采样来生成样本。

## 流模型(Flow Models)
通过定义一个可逆的变换将简单的先验分布映射到复杂的后验分布，从而实现样本的生成。流模型具有可解析的概率密度函数，可以进行高效的样本生成和概率推断。

## 概率扩散模型(Diffusion Probabilistic Models，DPMs)
通过迭代地应用概率扩散过程来生成样本如DDPM和常用于Stable Diffusion的DDIM与DPM++。DPMs也使用噪声作为输入。DPMS通过迭代的方式对声进行降，从而生成更准确的样本。噪声在这里被视为对真实样本的干扰，通过去除噪声来逐步恢复真实样本的信号。

### DDPM

1. DDPM
DDPM是一种概率扩散模型，它通过迭代地应用概率扩散过程来生成样本。DDPM使用噪声作为输入，并通过迭代的方式对噪声进行降，从而生成更准确的样本。噪声在这里被视为对真实样本的干扰，通过去除噪声来逐步恢复真实样本的信号。

2. DDPM的数学形式

加噪:
$$
x_t=\alpha x_{t-1}+\beta\epsilon_t
$$

其中$\alpha_t^2+\beta_t^2=1$
    
迭代:
$$
\begin{aligned}
x_t=&\alpha_t x_{t-1}+\beta_t\epsilon_t \\
   =&\alpha_{t}(\alpha_{t-1}x_{t-2}+\beta_{t-1}\epsilon_{t-1})+\beta_{t}\epsilon_t \\
   =& \dots
    
\end{aligned}   

$$





