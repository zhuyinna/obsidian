# 条件控制扩散模型

引入条件y，**条件扩散模型的前向过程与非条件扩散模型的前向过程完全一样**。

![Untitled](Untitled%2071.png)

## 1. classifier guidance

**Abstract：Classifier-Guidance: 对于大多数人来说，一个SOTA级别的扩散模型训练成本太大了，而分类器（Classifier）的训练还能接受，所以直接复用别人训练好的无条件扩散模型，用一个分类器来调整生成过程以实现控制生成。**

### 1.1 原理

![Untitled](Untitled%2072.png)

![Untitled](Untitled%2073.png)

![Untitled](Untitled%2074.png)

### 1.2 优缺点

**优点：**

可以直接用别人训好的大数据集下的无条件生成模型，直接自己训练一个分类模型，就可以进行采样生成条件下的生成数据。

**缺点：**

1. 在采样时，需要用到两个模型，采样效率比较低。

2. 在classifier-free-diffusion-guidance论文中，对于一个来自于三个高斯分布混合而成的分布，我们通过分类器引导的采样过程导致了采样结果严重受限于该分布的局部领域，且分类器引导强度越强，远离其他类别的质心的表现越明显，使得结果越加集中在局部空间。

![Untitled](Untitled%2075.png)

## 2. ****Classifier-free guidance****

**Abstract：往扩散模型的训练过程中就加入条件信号，达到更好的生成效果。**

### 2.1 原理

![Untitled](Untitled%2076.png)

？

**Classifier Guidance 使用显式的分类器引导条件生成有几个问题**：一是需要额外训练一个噪声版本的图像分类器。二是该分类器的质量会影响按类别生成的效果。三是通过梯度更新图像会导致对抗攻击效应，生成图像可能会通过人眼不可察觉的细节欺骗分类器，实际上并没有按条件生成。

2022年谷歌提出**Classifier-Free Guidance**方案，可以规避上述问题，而且可以通过调节引导权重，控制生成图像的逼真性和多样性的平衡，**DALL·E 2和Imagen等模型都是以它为基础进行训练和推理。**

**Classifier-Free Guidance的核心是通过一个隐式分类器来替代显示分类器，而无需直接计算显式分类器及其梯度**。根据贝叶斯公式，**分类器的梯度可以用条件生成概率和无条件生成概率表示**：

![Untitled](Untitled%2077.png)

![Untitled](Untitled%2078.png)

由上可知，新的生成过程**不再依赖显示的classifier**，因而解决了上述Classifier Guidance的几个问题。

**总的来说，训练时，Classifier-Free Guidance需要训练两个模型，一个是无条件生成模型，另一个是条件生成模型。**但这两个模型可以用同一个模型表示，**训练时只需要以一定概率将条件置空即可。**

**推理时，最终结果可以由条件生成和无条件生成的线性外推获得，生成效果可以引导系数可以调节，控制生成样本的逼真性和多样性的平衡。**

(引导系数一般是0.25)

### 2.2

优点：能改善引导分类器采样结果严重受限于该分布的局部领域的情况。

缺点：需要训练一个大模型

## 3. CLIP guidance

Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I. Learning transferable visual models from natural language supervision. arXiv:2103.00020, 2021.