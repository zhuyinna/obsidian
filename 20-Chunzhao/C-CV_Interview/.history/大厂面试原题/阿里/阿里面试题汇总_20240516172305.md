### 阿里面试题汇总

- resnet结构为啥要这么设计
ResNet (Residual Network) 的设计基于“残差学习”的概念，旨在解决深层网络中的梯度消失和梯度爆炸问题。通过引入残差块（每个块包含跳跃连接，允许梯度直接流向更浅的层），使得网络可以进行更深层次的训练而不丧失性能。跳跃连接有助于保持网络的训练稳定，并支持更深的网络结构，从而在不增加复杂度的情况下提高模型性能。
- relu 的优势
    - 非线性: 0处不可导
    - 计算简单,相比于tanh的4FLOPS, relu只有1FLOPS?
    - 解决梯度消失问题:正区间梯度恒为1
    - 提高网络的稀疏性
- 选择softmax的优势
    - 将logits转换为概率输出, 易于解释
    - 适用于多分类问题
    - 可微: 使得基于梯度的优化算法成为可能
- 常用哪些激活函数，leaky relu的优势
relu有可能导致神经元死亡, leaky relu避免这一点: 允许小的梯度值在输入为负数时流过
- 归一化的优点
    - 减少模型对参数初始化的敏感度
    - 改善优化过程,加速收敛
    - 减少过拟合(例如BN有一定正则化效果)
- SE的过程
SE块是一种网络结构，用于自适应地重新校准通道间的响应，通过显式建模通道间的依赖关系来增强网络的表达能力。它通过压缩空间信息（Squeeze）和激励特征通道（Excitation）来实现，通常可以显著提升网络性能。

- 对传统机器学习有没有太了解（答之前在比赛，没咋复习，可能不是很熟悉）

- 了解XGboost？
XGBoost（eXtreme Gradient Boosting）是一种高效的实现梯度提升算法的库，它被广泛用于机器学习竞赛和实际问题中。XGBoost的优势在于速度快、性能好，支持并行处理，并且可以处理各种类型的数据。它通过构建多个弱分类器的集成模型，逐步提升模型性能，从而实现对复杂数据的高效建模。
> 什么是梯度提升算法? 

- yolo系列的发展史
- 对yolov4中的csp结构有无了解
- 想问logistic回归相关问题
- 
