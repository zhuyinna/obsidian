# 一面

- 问实习做的项目以及具体的细节（搭了哪些backbone，有没有用迁移学习，MAE怎么计算...）
  - 可能会使用不同的backbone网络，例如VGG、ResNet、Inception等，作为模型的特征提取部分。迁移学习可能会被用来利用预训练模型在大型数据集（如ImageNet）上学到的知识，以加速训练过程并提高模型的泛化能力。MAE（平均绝对误差）通常是通过计算预测值和真实值之间差的绝对值的平均来计算的。
- 问自己的小项目的细节（数据合成怎么做的，用了哪些数据增强，了解mixup吗...）
  - 数据合成可能涉及使用图像合成技术来生成训练数据，例如通过将前景对象叠加到不同的背景中。数据增强可能包括随机裁剪、旋转、缩放、颜色变换等技术。Mixup是一种数据增强技术，它通过在样本对之间进行线性插值来创建新样本。
  - Mixup代码实现:
    ```python
    def mixup_data(x, y, alpha=1.0, use_cuda=True):
        if alpha > 0:
            lam = np.random.beta(alpha, alpha)
        else:
            lam = 1
        batch_size = x.size()[0]
        if use_cuda:
            index = torch.randperm(batch_size).cuda()
        else:
            index = torch.randperm(batch_size)
        mixed_x = lam * x + (1 - lam) * x[index, :]  # 对输入数据进行线性插值
        y_a, y_b = y, y[index]
        return mixed_x, y_a, y_b, lam
    ```
- detection的经典的baseline了解哪些，说一说？
  - R-CNN系列: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN
  - YOLO系列: YOLOv1, YOLOv2, YOLOv3, YOLOv4
  - SSD: Single Shot MultiBox Detector
- Mask RCNN 如何解决 unalignment?
  - 通过引入一个额外的分支来预测目标的mask，ROI Align通过双线性插值精确地对齐感兴趣区域（RoI）和特征图，避免了ROI Pooling中由于量化而导致的不精确对齐。
  > ROI pooling是将RoI映射到固定大小的特征图上，但由于量化的原因，可能导致RoI和特征图之间的不精确对齐，从而影响了mask的精度。ROI Align通过双线性插值来解决这个问题，保证了RoI和特征图之间的精确对齐。
- RFCN里的 position sensitive score map 的原理？解决了什么问题？
  - RFCN(Region-based Fully Convolutional Networks)通过将RoI划分为多个位置敏感区域，然后对每个区域进行分类和回归，从而提高了目标检测的精度。这种方法可以更好地对齐目标的位置，提高了检测的准确性。
- 说说 Anchor-based 和 Anchor Free 的区别
  - Anchor-based方法（如Faster R-CNN）依赖于预定义的锚框来预测目标的位置，而Anchor Free方法（如CenterNet、FCOS）直接在特征图上预测目标的位置和大小，不依赖于预定义的锚框。
  - Anchor-based方法更快, 但是需要设计和调参锚框, 容易出现重叠问题; Anchor Free方法不需要设计锚框, 直接预测目标的位置和大小, 但是速度较慢.
- ROC 和 AUC
  - ROC(Receiver Operating Characteristic)曲线是用于评估**二分类器的性能**，横轴是假阳性率（False Positive Rate），纵轴是真阳性率（True Positive Rate）。AUC（Area Under Curve）是ROC曲线下的面积，用于衡量分类器的性能，AUC值越大，分类器的性能越好。
- mAP 和 AUC 各自的优缺点
  - mAP（mean Average Precision）是目标检测任务中常用的评价指标，它综合考虑了不同类别的AP（Average Precision），可以更全面地评估模型的性能。AUC（Area Under Curve）是用于评估二分类器的性能，它只考虑了真阳性率和假阳性率，不能直接用于目标检测任务。

# 二面

- 你说你实习用过ShuffleNet，那ShuffleNet-v1,v2各有什么优点，motivation是什么？
  - ShuffleNet-v1
    - 通过Channel Shuffle来增加通道之间的信息交流，利用分组卷积减少参数量和计算量，提高模型的效率。
    >分组卷积: 将输入通道分成多个组，每个组进行卷积操作，然后将结果拼接在一起。这样可以减少参数量和计算量，提高模型的效率。
    - motivation: 减少参数量和计算量，提高模型的效率。
  - ShuffleNet-v2
    - 在v1的基础上引入了瓶颈结构，先降维再升维，进一步减少了计算量，提高了模型的性能, 减少了内存访问成本(MAC)
    - motivatin: 进一步减少计算量，提高模型的性能。
- Channel Shuffle Pytorch里面是怎么实现的？如果用 Tensorflow 呢？
```python
def channel_shuffle(x, groups):
    batchsize, num_channels, height, width = x.data.size()
    channels_per_group = num_channels // groups
    # reshape
    x = x.view(batchsize, groups, channels_per_group, height, width)
    x = torch.transpose(x, 1, 2).contiguous()  
    # flatten
    x = x.view(batchsize, -1, height, width)
    return x
```
```python
def channel_shuffle(x, groups):
    batchsize, height, width, num_channels = x.shape.as_list()
    channels_per_group = num_channels // groups
    # reshape
    x = tf.reshape(x, [-1, height, width, groups, channels_per_group])
    x = tf.transpose(x, [0, 1, 2, 4, 3])
    # flatten
    x = tf.reshape(x, [-1, height, width, num_channels])
```
> transpose操作是将张量的维度进行交换, 通过transpose操作可以实现张量的维度变换, 从而实现通道之间的交换。

- 你还用过Mobilenet，问个最简单的，Pytorch里怎么实现DwConv？
  - Depthwise Convolution（深度卷积）是MobileNet中的一个重要组件，它通过对每个输入通道进行单独的卷积操作，然后将结果进行通道拼接，从而减少参数量和计算量。
  ```python
  def dw_conv(in)
  ```
- 现在有一 NCHW 的 feature map，经过一个3*3的DwConv，计算量和参数量怎么算？
- v2的瓶颈块里为什么要先升维再降维？这不是增加了计算量吗？
- 说说 v3 里的 h-swish比普通的swish激活函数好在哪里？通道注意力机制的原理？
- FPN的上采样怎么做的？会带来什么后果？模型中是怎么解决的？
- FCN的上采样又是怎么做的？你认为双线性插值和反卷积哪个效果会更好？
- SSD的基本原理讲一讲？Anchor怎么选的？NMS怎么做的？
- U-NET的特征融合怎么做的？
- Linux cat 命令的作用？
- Docker磁盘映射的参数是什么？
- 给一个特定的任务，针对这个任务设计Loss，说说思路？
- 现有数以十万计的两个图片文件夹，其中一个被另一个包含，最快找出两个文件夹的差集，说说思路？


# coding

coding: 一面
1. 连续子数组最大和
2. 计算IOU

coding: 二面
1. 反转链表，不用递归
2. TopK，面试官说写一个解决办法就行，然后让我讲我知道的思路
反问
