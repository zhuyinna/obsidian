# 一面

- 问实习做的项目以及具体的细节（搭了哪些backbone，有没有用迁移学习，MAE怎么计算...）
  - 可能会使用不同的backbone网络，例如VGG、ResNet、Inception等，作为模型的特征提取部分。迁移学习可能会被用来利用预训练模型在大型数据集（如ImageNet）上学到的知识，以加速训练过程并提高模型的泛化能力。MAE（平均绝对误差）通常是通过计算预测值和真实值之间差的绝对值的平均来计算的。
- 问自己的小项目的细节（数据合成怎么做的，用了哪些数据增强，了解mixup吗...）
  - 数据合成可能涉及使用图像合成技术来生成训练数据，例如通过将前景对象叠加到不同的背景中。数据增强可能包括随机裁剪、旋转、缩放、颜色变换等技术。Mixup是一种数据增强技术，它通过在样本对之间进行线性插值来创建新样本。
  - Mixup代码实现:
    ```python
    def mixup_data(x, y, alpha=1.0, use_cuda=True):
        if alpha > 0:
            lam = np.random.beta(alpha, alpha)
        else:
            lam = 1
        batch_size = x.size()[0]
        if use_cuda:
            index = torch.randperm(batch_size).cuda()
        else:
            index = torch.randperm(batch_size)
        mixed_x = lam * x + (1 - lam) * x[index, :]  # 对输入数据进行线性插值
        y_a, y_b = y, y[index]
        return mixed_x, y_a, y_b, lam
    ```
- detection的经典的baseline了解哪些，说一说？
  - R-CNN系列: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN
  - YOLO系列: YOLOv1, YOLOv2, YOLOv3, YOLOv4
  - SSD: Single Shot MultiBox Detector
- Mask RCNN 如何解决 unalignment?
  - 通过引入一个额外的分支来预测目标的mask，ROI Align通过双线性插值精确地对齐感兴趣区域（RoI）和特征图，避免了ROI Pooling中由于量化而导致的不精确对齐。
  > ROI pooling是将RoI映射到固定大小的特征图上，但由于量化的原因，可能导致RoI和特征图之间的不精确对齐，从而影响了mask的精度。ROI Align通过双线性插值来解决这个问题，保证了RoI和特征图之间的精确对齐。
RFCN里的 position sensitive score map 的原理？解决了什么问题？
说说 Anchor-based 和 Anchor Free 的区别
ROC 和 AUC
mAP 和 AUC 各自的优缺点

# 二面

你说你实习用过ShuffleNet，那ShuffleNet-v1,v2各有什么优点，motivation是什么？
Channel Shuffle Pytorch里面是怎么实现的？如果用 Tensorflow 呢？
你还用过Mobilenet，问个最简单的，Pytorch里怎么实现DwConv？
现在有一 NCHW 的 feature map，经过一个3*3的DwConv，计算量和参数量怎么算？
v2的瓶颈块里为什么要先升维再降维？这不是增加了计算量吗？
说说 v3 里的 h-swish比普通的swish激活函数好在哪里？通道注意力机制的原理？
FPN的上采样怎么做的？会带来什么后果？模型中是怎么解决的？
FCN的上采样又是怎么做的？你认为双线性插值和反卷积哪个效果会更好？
SSD的基本原理讲一讲？Anchor怎么选的？NMS怎么做的？
U-NET的特征融合怎么做的？
Linux cat 命令的作用？
Docker磁盘映射的参数是什么？
给一个特定的任务，针对这个任务设计Loss，说说思路？
现有数以十万计的两个图片文件夹，其中一个被另一个包含，最快找出两个文件夹的差集，说说思路？

coding: 一面
1.连续子数组最大和
2.计算IOU


coding: 二面
1.反转链表，不用递归
2.TopK，面试官说写一个解决办法就行，然后让我讲我知道的思路
反问
