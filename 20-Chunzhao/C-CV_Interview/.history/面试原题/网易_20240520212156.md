
- 你这个borderline smote + mixup 怎么做的？
  - Borderline SMOTE：这是一种过采样技术，用于处理不平衡数据集。它特别关注那些在决策边界附近的少数类样本，并只对这些样本进行SMOTE(Synthetic Minority Over-Sampling Technique, 合成少数过采样技术)
  - Mixup：这是一种数据增强技术，通过线性地混合两个样本及其标签来生成新的训练样本。
  - 结合这两种方法可以生成新的样本，既考虑到了类别平衡也增加了数据多样性。
- ResNet有什么优点？解决了什么问题？
  - 残差结构: 环节梯度消失和梯度爆炸, 增加网络深度
- Inception-v1的创新点？v3中3*3卷积分解怎么做的？
  - 引入Inception模块,它允许网络在同一个层级上学习多种尺度的特征。
  - Inception-v3中的创新点包括将较大的卷积核（如3x3）分解成较小的卷积（如1x3和3x1），这样做可以减少参数数量，提高网络效率。
- 3D卷积
  - 3D卷积通常用于处理视频或体积数据，它可以同时捕获空间和时间维度上的特征。
- Batch Normalization的具体过程？为什么要有两个可学习参数？
  - 目标: 加速深度网络训练
  - **它通过规范化层的输入来减少内部协变量偏移。具体过程包括计算批次数据的均值和方差，然后使用这些统计数据来规范化数据，最后通过可学习的参数γ（尺度）和β（偏移）来恢复和保持网络的表达能力。**
- 

为啥要对近邻数据做类别判断？



说说它和其他几种Normalization的区别以及各自的应用场景？
Anchor Free的目标检测网络有哪些？具体说说各自的基本原理？
目标检测领域的常见Loss？
讲讲逻辑回归的思路
smooth L1 loss 的优点？
IoU Loss的表达式？有什么缺点？如何改进？
讲讲SVD的过程
SVD怎么用到PCA降维里面？（说的比较散，卒）
那你说说PCA降维的过程吧，和 LDA 有什么联系和区别，应用场景分别是什么？
one-stage和two-stage的区别，以及各自的典型网络有哪些？
讲讲 FCOS 的模型结构和基本原理？（没了解过，完全卒）
面试官：我们继续吧，CV三大领域的SOTA算法你了解哪些？



coding
1. 合并k个有序链表，保持合并后的链表有序，要求最低的时间复杂度内完成（写得很艰难）
```cpp
TreeNode* sortTwoList(TreeNode* head1, TreeNode* head2) {
    if ( !head1 ) return head2;
    if ( !head2 ) return head1;

}
```
2. 数组中只有两个数出现了一次，其它数都出现两次，常数空间复杂度内找出这两个数


