VGGNet: 是牛津大学计算机视觉组在2014年提出的模型, 通过多个卷积层和池化层的堆叠来构建深度网络, 以提高网络的性能. VGGNet的网络结构非常简单, 但是却非常有效, 在ILSVRC2014比赛中取得了第二名的成绩. VGGNet的网络结构如下图所示:

<img src=https://s2.loli.net/2024/05/07/Hq2CDiUhsfw3npW.png width='50%'>
<img src=https://s2.loli.net/2024/05/07/RELfSi85KzJa1Nj.png width='50%'>

其中VGG16和VGG19效果较好, 分别为D和E. 这6种网络结构相似，都是由5层卷积层、3层全连接层组成，区别在于每个卷积层的子层数量不同，从A至E依次增加，总的网络深度从11层到19层。表格中的卷积层参数表示为“conv（感受野大小）-通道数”，例如con3-64，表示使用3x3的卷积核，通道数为64；最大池化表示为maxpool，层与层之间使用maxpool分开；全连接层表示为“FC-神经元个数”，例如FC-4096表示包含4096个神经元的全连接层；最后是softmax层。

以VGG16为例(D): 第1层卷积层由2个conv3-64组成，第2层卷积层由2个conv3-128组成，第3层卷积层由3个conv3-256组成，第4层卷积层由3个conv3-512组成，第5层卷积层由3个conv3-512组成，然后是2个FC4096，1个FC1000。总共16层，这也就是VGG16名字的由来。

1. 输入层
224x224x3
2. 第一层 卷积层
第1层卷积层由2个conv3-64组成。
- 卷积: 3x3x3 64个, padding=1, stride=1
    -> 224x224x64
- Relu
卷积: 3x3x64 64个, padding=1, stride=1
    -> 224x224x64
Relu
池化: 2x2 stride=2, 最大池化
    -> 112x112x64

3. 第二层 卷积层
卷积: 输入是112x112x64，使用128个3x3x64的卷积核进行卷积，padding=1，stride=1,
    -> 112x112x128
Relu
卷积: 输入是112x112x128，使用128个3x3x128的卷积核进行卷积，padding=1，stride=1，根据公式
    -> 112x112x128
Relu
池化: 使用2x2，stride=2的池化单元, 最大池化
    -> 56x56x128
4. 第三层 卷积层
卷积