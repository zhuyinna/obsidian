# Transformer & UNet

1. 计算资源
Transformer是一个非常大的模型，需要大量的计算资源。在训练时，我们需要大量的显存，通常需要32GB以上的显存。在推理时，我们需要大量的计算资源，通常需要8个以上的GPU。因此，我们需要在训练和推理时使用大量的计算资源。
而CNN（如Unet）在处理图像数据时更加高效，因为它们通过局部卷积操作减少了参数数量和计算量。
2. 感受野和局部特征提取
Transformer是一个全局特征提取模型，它可以捕获全局特征，但不能捕获局部特征。UNet是一个局部特征提取模型，它可以捕获局部特征，但不能捕获全局特征。

**信息融合**:在图像分割等任务中，结合局部和全局信息通常可以获得更好的结果。Unet提供了有效的局部信息提取和多尺度特征融合的框架，而Transformer增加了对全局依赖关系的处理能力。两者结合可以使得模型在保持细节的同时，也能够理解图像的整体结构。


# 融合方式

## Transformer作为编码器

在这种结构中，Transformer完全替代Unet中的编码部分，用以捕获全局依赖关系。编码后的特征图再通过传统的Unet解码器进行上采样和恢复到原始尺寸。

## Transformer块插入

在Unet的编码器或解码器中的特定层后面插入Transformer块，以增强模型对全局信息的处理能力。这种方法可以视为是对Unet结构的“增强”而非完全替换。

## 注意力增强的跳跃连接

利用Transformer中的自注意力机制改进Unet的跳跃连接，使网络在合并来自不同尺度的特征时能更加精确地对重要特征进行选择和强调。