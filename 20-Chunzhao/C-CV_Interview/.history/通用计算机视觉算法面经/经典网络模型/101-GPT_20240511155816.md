# 词向量的历史
- 词向量的历史
    - 2003年，Bengio等人提出了神经网络语言模型（NNLM），并在2008年提出了词嵌入模型（Word Embedding）。
    - 2013年，Mikolov等人提出了word2vec模型，该模型是一个高效的词向量学习模型，可以学习出高质量的词向量。
    - 2014年，Pennington等人提出了GloVe模型，该模型是一个基于全局词频统计的词向量学习模型，可以学习出高质量的词向量。
    - 2018年，Devlin等人提出了BERT模型，该模型是一个基于Transformer的预训练模型，可以学习出高质量的词向量。
    - 2019年，Liu等人提出了RoBERTa模型，该模型是一个基于BERT的预训练模型，可以学习出高质量的词向量。
    - 2019年，Yang等人提出了XLNet模型，该模型是一个基于Transformer的预训练模型，可以学习出高质量的词向量。
    - 2019年，Lan等人提出了ALBERT模型，该模型是一个基于BERT的预训练模型，可以学习出高质量的词向量。
    - 2019年，Sanh等人提出了DistilBERT模型，该模型是一个基于BERT的预训练模型，可以学习出高质量的词向量。
    - 2019年，Liu等人提出了ERNIE模型，该模型是一个基于BERT的预训练模型，可以学习出高质量的词向量。
    - 2019年，Sun等人提出了SimBERT模型，该模型是一个基于BERT的预训练模型，可以学习出高质量的词向量。
  