### 面试题

[1. 简述AI任务中常见的指标](常用指标.md)

[2. 简述你知道的激活函数](激活函数)

[3. 说一下感受野](描述一下感受野.md)

[4.权重初始化的方法？ ](权重初始化的方法.md)

[5. 描述一下优化算法](优化算法.md)

[6. add与concat之间的区别](add_with_concat.md)

[7. 说一下bp](bp举例.md)

[8. 描述下cv中的attention](CV中的Attention.md)

[9. 描述下DenseNet](DenseNet.md)

[10. dropout上](dropout_1.md)

[11. dropout下(为什么Dropout与BN不和谐共处)](dropout_2.md)

[12. 在Backbone不变的情况下，若显存有限，如何增大训练时的batchsize](enlarge_bs.md)

[13. 描述一下IOU](IOU.md)

[14. 描述一下L1与L2的比较](L1与L2正则的比较.md)

[15. labelsmoothing的数学推导等](labelsmoothing.md)

[16. 各种归一化的汇总](normalization.md)

[17. 你了解的重参数技巧](reparameter.md)

[18. 具体阐述一下ResNet网络的细节，你知道的ResNet网络的相关变种有哪些](resnet.md)

[19. sigmoid与softmax的区别与联系](sigmoid与softmax的区别与联系.md)

[20. softmax及其相关变形](softmax及其相关变形.md)

[21. 描述下1 x1卷积](1x1.md)

[22. 说一下im2col](im2col.md)

[23. 说一下RNN/LSTM/GRU等优势与劣势](你知道的时序建模模块.md)

[24. 写一下NMS](nms.md)

[25. NMS存在哪些优化](NMS及其优化.md)

[26. CNN参数与卷积输出大小计算](conv.md)

[27. 出现过拟合怎么办？](出现过拟合怎么办.md)

[28. 为什么深度学习模型初始化参数不能为0？](为什么深度学习模型初始化参数不能为0.md)

[29. 神经网络模型不收敛，有哪些原因？](神经网络模型不收敛.md)

## 写代码

[1. 全连接层前向与反向传播代码](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[2. Dropout前向与反向](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[3. 激活函数之ReLu/Sigmoid/Tanh前向与反向传播](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[4. 卷积层与池化层前向与反向传播](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[5. BatchNorm2d前向反向传播](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[6. Flatten层前向与反向传播](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[7. 交叉熵损失函数前向与反向传播](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
[8. 优化器代码](https://mp.weixin.qq.com/s?__biz=MzkzNDIxMzE1NQ==&mid=2247488876&idx=1&sn=7566b562e7ec92c7b45686c6c1ece52c&chksm=c241f620f5367f36c85c85a91dc81c068d900961c0a65dc202373427b6b11b0459e828973eeb&token=2036211154&lang=zh_CN#rd)  
