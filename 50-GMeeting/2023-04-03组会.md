---
Date: 2023-04-03
Presenter: 王依婷, 童逸轩
DESC: BERT;dreamfusion;
---
tags:  #组会 

## 分享一
***
### Title
![[Pasted image 20230403190333.png]]


### Transformer

测试的时候不能并行

训练： decoder 并行

![[Pasted image 20230403191146.png]]


### BERT

![[Pasted image 20230403191508.png]]

创新点：预训练
MLM：masked language modeling
       ![[Pasted image 20230403191815.png|575]]
1. masked；
    业界一般：在 pre-train 的基础上进行 finetune
    ![[Pasted image 20230403192238.png|500]]
    masked 策略的目的：对所有 token，不止[mask]敏感
2. A 和 B 的句子是否上下文；
     ![[Pasted image 20230403192508.png|500]]

Fine-Tuning 比较快
pretrain 比较费时

## 分享二
***
### title
dreamfusion
创新点：score distillation loss
